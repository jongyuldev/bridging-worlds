# Bridging Worlds - Documentation Index

Welcome to the **Bridging Worlds** documentation! This project provides AI-powered accessibility tools for communication and environmental awareness.

## ğŸ“š Documentation Overview

### Main Documentation
- **[README.md](../README.md)** - Project overview, installation, and quick start guide

### Feature-Specific Guides

#### 1. Sign Language Interpreter
ğŸ“– **[Sign Language Interpreter - Complete Guide](hand_keypoint_tts_usage.md)**

The most advanced feature! Real-time sign language interpretation with:
- 21-point hand keypoint detection
- Dual-hand tracking
- Text-to-Speech integration
- Interactive learning mode
- Mirror-corrected display

**Quick Start**: `python src/hand_keypoint_detection.py`

---

#### 2. AI Vision Assistant
ğŸ“– **[Vision Assistant Guide](vision_assistant_guide.md)**

Intelligent object detection and scene understanding:
- Real-time object detection (80+ classes)
- Natural language scene descriptions
- Audio feedback for accessibility
- Spatial awareness and tracking

**Quick Start**: 
- Full version: `python src/vision_assistant.py`
- Simple version: `python src/simple_vision_assistant.py`

---

## ğŸš€ Quick Reference

### All Available Programs

| Program | Command | Purpose |
|---------|---------|---------|
| **Sign Language Interpreter** | `python src/hand_keypoint_detection.py` | Real-time sign interpretation with TTS |
| **Vision Assistant** | `python src/vision_assistant.py` | AI object detection with scene description |
| **Simple Vision Assistant** | `python src/simple_vision_assistant.py` | Streamlined object detection |
| **ASL Alphabet Translator** | `python src/asl_translator.py` | Trained ASL alphabet recognition |
| **Basic Sign Recognition** | `python src/sign_language.py` | Simple gesture detection |

### Common Controls

| Key | Function | Used In |
|-----|----------|---------|
| **SPACE** | Next word / Advance | Sign Language Interpreter |
| **R** | Reset | Sign Language Interpreter |
| **S** | Scene description / Save | Vision Assistant / Interpreter |
| **L** | Toggle labels | Sign Language Interpreter |
| **K** | Toggle visualization | Sign Language Interpreter |
| **Q** | Quit | All programs |

---

## ğŸ¯ Use Case Guide

### I want to...

**...interpret sign language in real-time**
â†’ [Sign Language Interpreter Guide](hand_keypoint_tts_usage.md)  
â†’ Run: `python src/hand_keypoint_detection.py`

**...learn sign language**
â†’ [Sign Language Interpreter - Learning Mode](hand_keypoint_tts_usage.md#learning-mode-demonstration)  
â†’ Use the interactive word-by-word progression feature

**...detect objects for accessibility**
â†’ [Vision Assistant Guide](vision_assistant_guide.md)  
â†’ Run: `python src/vision_assistant.py`

**...recognize ASL alphabet**
â†’ [README - ASL Recognition](../README.md#option-4-advanced-asl-alphabet-recognition)  
â†’ Train model: `python src/train_asl_model.py`  
â†’ Run: `python src/asl_translator.py`

---

## ğŸ”§ Technical Documentation

### Architecture Overview

```
Bridging Worlds Platform
â”‚
â”œâ”€â”€ Sign Language Interpretation
â”‚   â”œâ”€â”€ MediaPipe Hands (21 landmarks)
â”‚   â”œâ”€â”€ Gesture Recognition Engine
â”‚   â”œâ”€â”€ Text-to-Speech (Windows SAPI)
â”‚   â””â”€â”€ Visual Feedback System
â”‚
â”œâ”€â”€ Vision Assistance
â”‚   â”œâ”€â”€ YOLOv8 Object Detection
â”‚   â”œâ”€â”€ Scene Analysis Engine
â”‚   â”œâ”€â”€ Spatial Relationship Parser
â”‚   â””â”€â”€ Audio Description Generator
â”‚
â””â”€â”€ ASL Alphabet Recognition
    â”œâ”€â”€ CNN Deep Learning Model
    â”œâ”€â”€ Real-time Inference
    â”œâ”€â”€ Confidence Scoring
    â””â”€â”€ Translation Buffer
```

### Key Technologies

- **MediaPipe**: Hand tracking and landmark detection
- **YOLOv8**: Real-time object detection
- **PyTorch**: Deep learning framework
- **OpenCV**: Computer vision and camera handling
- **Windows SAPI**: Text-to-Speech synthesis
- **NumPy**: Numerical computations

---

## ğŸ“– Additional Resources

### Getting Help

- **GitHub Issues**: [Report bugs or request features](https://github.com/jongyuldev/bridging-worlds/issues)
- **Discussions**: Join conversations in the repository
- **Contact**: Reach out to jongyuldev on GitHub

### External Learning Resources

#### Sign Language
- [Start ASL](https://www.startasl.com/) - Free ASL lessons
- [Handspeak](https://www.handspeak.com/) - ASL dictionary
- [ASL University](https://www.lifeprint.com/) - Comprehensive courses

#### Technical Skills
- [MediaPipe Documentation](https://google.github.io/mediapipe/)
- [OpenCV Python Tutorials](https://docs.opencv.org/master/d6/d00/tutorial_py_root.html)
- [PyTorch Tutorials](https://pytorch.org/tutorials/)
- [YOLOv8 Documentation](https://docs.ultralytics.com/)

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Read the Code**
   - Browse `src/` for implementation details
   - Check comments and docstrings
   - Understand the architecture

2. **Try the Features**
   - Run all programs
   - Test different scenarios
   - Note what works and what doesn't

3. **Make Improvements**
   - Fix bugs
   - Add features
   - Improve documentation
   - Optimize performance

4. **Submit Changes**
   - Fork the repository
   - Create a feature branch
   - Make your changes
   - Submit a pull request

---

## ğŸ“‹ Changelog

### Version 1.0 (Current)
- âœ… Sign Language Interpreter with TTS
- âœ… 21-point hand keypoint detection
- âœ… Dual-hand tracking
- âœ… AI Vision Assistant
- âœ… YOLOv8 object detection
- âœ… Mirror-corrected camera display
- âœ… Interactive learning mode
- âœ… Comprehensive documentation

### Planned Features
- ğŸ”² Full ASL vocabulary recognition
- ğŸ”² Sentence-level interpretation
- ğŸ”² Multi-language sign support
- ğŸ”² Mobile app versions
- ğŸ”² Cloud-based processing
- ğŸ”² Video call integration

---

## ğŸ“„ License

This project is open source under the MIT License. See LICENSE file for details.

---

## ğŸ‘¥ Credits

**Developed by**: jongyuldev  
**Repository**: [github.com/jongyuldev/bridging-worlds](https://github.com/jongyuldev/bridging-worlds)

### Acknowledgments
- MediaPipe team at Google
- YOLOv8 by Ultralytics
- PyTorch contributors
- The deaf and hard-of-hearing community
- All open source contributors

---

**Made with â¤ï¸ to bridge communication barriers**

*Empowering communication through AI - One gesture at a time.*

---

[â¬†ï¸ Back to Top](#bridging-worlds---documentation-index)
